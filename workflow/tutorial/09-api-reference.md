# ç¬¬ä¹ç« ï¼šAPI å‚è€ƒæ–‡æ¡£

## æ ¸å¿ƒç±»å’Œæ–¹æ³•

### Agent ç±»

#### åŸºæœ¬ç”¨æ³•

```python
from fastagent import Agent

# åˆ›å»ºä»£ç†
agent = Agent(
    instructions="You are a helpful assistant",
    model="anthropic.claude-3-sonnet-latest",
    name="my_agent"
)
```

#### Agent æ„é€ å‡½æ•°

```python
class Agent:
    def __init__(
        self,
        instructions: str = None,
        model: str = None,
        name: str = None,
        mcp_servers: List[str] = None,
        system_prompt: str = None,
        temperature: float = None,
        max_tokens: int = None,
        tools: List[Dict] = None,
        **kwargs
    ):
        """
        åˆ›å»ºæ–°çš„ Agent å®ä¾‹
        
        Args:
            instructions: ä»£ç†çš„æŒ‡ä»¤æˆ–è§’è‰²æè¿°
            model: è¦ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼ˆå¦‚ "anthropic.claude-3-sonnet-latest"ï¼‰
            name: ä»£ç†çš„åç§°ï¼Œç”¨äºæ ‡è¯†å’Œæ—¥å¿—
            mcp_servers: è¦è¿æ¥çš„ MCP æœåŠ¡å™¨åˆ—è¡¨
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¦‚æœä¸ä½¿ç”¨ instructionsï¼‰
            temperature: ç”Ÿæˆæ¸©åº¦ (0.0-1.0)
            max_tokens: æœ€å¤§ç”Ÿæˆä»¤ç‰Œæ•°
            tools: å¯ç”¨å·¥å…·åˆ—è¡¨
            **kwargs: å…¶ä»–æ¨¡å‹ç‰¹å®šå‚æ•°
        """
```

#### ä¸»è¦æ–¹æ³•

##### send() æ–¹æ³•

```python
async def send(
    self,
    message: str,
    context: Dict[str, Any] = None,
    stream: bool = False,
    **kwargs
) -> str:
    """
    å‘ä»£ç†å‘é€æ¶ˆæ¯å¹¶è·å–å“åº”
    
    Args:
        message: è¦å‘é€çš„æ¶ˆæ¯
        context: ä¸Šä¸‹æ–‡ä¿¡æ¯å­—å…¸
        stream: æ˜¯å¦å¯ç”¨æµå¼å“åº”
        **kwargs: å…¶ä»–å‚æ•°
    
    Returns:
        ä»£ç†çš„å“åº”å­—ç¬¦ä¸²
    
    Raises:
        AgentError: ä»£ç†æ‰§è¡Œé”™è¯¯
        ModelError: æ¨¡å‹è°ƒç”¨é”™è¯¯
        MCPError: MCP æœåŠ¡å™¨é”™è¯¯
    """

# ä½¿ç”¨ç¤ºä¾‹
response = await agent.send("Hello, how are you?")
print(response)

# å¸¦ä¸Šä¸‹æ–‡
context = {"user_id": "123", "session_id": "abc"}
response = await agent.send("What's my order status?", context=context)

# æµå¼å“åº”
async for chunk in agent.send("Tell me a story", stream=True):
    print(chunk, end="")
```

##### interact() æ–¹æ³•

```python
async def interact(
    self,
    initial_message: str = None,
    max_turns: int = None,
    exit_keywords: List[str] = None
) -> List[Dict[str, str]]:
    """
    å¯åŠ¨äº¤äº’å¼ä¼šè¯
    
    Args:
        initial_message: åˆå§‹æ¶ˆæ¯
        max_turns: æœ€å¤§è½®æ¬¡
        exit_keywords: é€€å‡ºå…³é”®è¯åˆ—è¡¨
    
    Returns:
        å¯¹è¯å†å²åˆ—è¡¨
    """

# ä½¿ç”¨ç¤ºä¾‹
history = await agent.interact(
    initial_message="Hello!",
    max_turns=10,
    exit_keywords=["bye", "exit", "quit"]
)
```

##### apply_prompt() æ–¹æ³•

```python
async def apply_prompt(
    self,
    prompt_name: str,
    arguments: Dict[str, Any] = None
) -> str:
    """
    åº”ç”¨ MCP æç¤º
    
    Args:
        prompt_name: æç¤ºåç§°
        arguments: æç¤ºå‚æ•°
    
    Returns:
        åº”ç”¨æç¤ºåçš„å“åº”
    """

# ä½¿ç”¨ç¤ºä¾‹
response = await agent.apply_prompt(
    "analyze_code",
    arguments={"code": "def hello(): print('world')"}
)
```

##### use_resource() æ–¹æ³•

```python
async def use_resource(
    self,
    resource_uri: str,
    operation: str = "read"
) -> Any:
    """
    ä½¿ç”¨ MCP èµ„æº
    
    Args:
        resource_uri: èµ„æº URI
        operation: æ“ä½œç±»å‹ï¼ˆread, write, list ç­‰ï¼‰
    
    Returns:
        èµ„æºå†…å®¹æˆ–æ“ä½œç»“æœ
    """

# ä½¿ç”¨ç¤ºä¾‹
content = await agent.use_resource("file:///path/to/file.txt")
files = await agent.use_resource("file:///path/to/directory", "list")
```

#### å±æ€§å’Œé…ç½®

```python
# è®¿é—®ä»£ç†å±æ€§
print(agent.name)           # ä»£ç†åç§°
print(agent.model)          # ä½¿ç”¨çš„æ¨¡å‹
print(agent.instructions)   # ä»£ç†æŒ‡ä»¤
print(agent.mcp_servers)    # è¿æ¥çš„ MCP æœåŠ¡å™¨

# åŠ¨æ€ä¿®æ”¹é…ç½®
agent.temperature = 0.7
agent.max_tokens = 2000

# æ·»åŠ å·¥å…·
agent.add_tool({
    "name": "calculator",
    "description": "Perform calculations",
    "parameters": {
        "type": "object",
        "properties": {
            "expression": {"type": "string"}
        }
    }
})
```

### Workflow ç±»

#### åŸºæœ¬ç”¨æ³•

```python
from fastagent import Workflow

# ä»æ–‡ä»¶åŠ è½½å·¥ä½œæµ
workflow = Workflow.from_file("my_workflow.yaml")

# ä»å­—å…¸åˆ›å»ºå·¥ä½œæµ
workflow_config = {
    "name": "analysis_workflow",
    "type": "chain",
    "steps": [
        {"agent": "analyzer", "input_key": "text", "output_key": "analysis"},
        {"agent": "summarizer", "input_key": "analysis", "output_key": "summary"}
    ]
}
workflow = Workflow.from_dict(workflow_config)
```

#### Workflow æ„é€ å‡½æ•°

```python
class Workflow:
    def __init__(
        self,
        name: str,
        workflow_type: str,
        steps: List[Dict],
        agents: Dict[str, Agent] = None,
        config: Dict[str, Any] = None
    ):
        """
        åˆ›å»ºå·¥ä½œæµå®ä¾‹
        
        Args:
            name: å·¥ä½œæµåç§°
            workflow_type: å·¥ä½œæµç±»å‹ï¼ˆchain, parallel, human_input ç­‰ï¼‰
            steps: å·¥ä½œæµæ­¥éª¤åˆ—è¡¨
            agents: ä»£ç†å­—å…¸
            config: å·¥ä½œæµé…ç½®
        """
```

#### ä¸»è¦æ–¹æ³•

##### run() æ–¹æ³•

```python
async def run(
    self,
    input_data: Dict[str, Any],
    context: Dict[str, Any] = None
) -> Dict[str, Any]:
    """
    è¿è¡Œå·¥ä½œæµ
    
    Args:
        input_data: è¾“å…¥æ•°æ®
        context: æ‰§è¡Œä¸Šä¸‹æ–‡
    
    Returns:
        å·¥ä½œæµè¾“å‡ºç»“æœ
    
    Raises:
        WorkflowError: å·¥ä½œæµæ‰§è¡Œé”™è¯¯
        ValidationError: è¾“å…¥éªŒè¯é”™è¯¯
    """

# ä½¿ç”¨ç¤ºä¾‹
result = await workflow.run({
    "text": "This is a document to analyze",
    "options": {"detailed": True}
})

print(result["summary"])  # è®¿é—®è¾“å‡º
```

##### validate() æ–¹æ³•

```python
def validate(self) -> List[str]:
    """
    éªŒè¯å·¥ä½œæµé…ç½®
    
    Returns:
        éªŒè¯é”™è¯¯åˆ—è¡¨ï¼ˆç©ºåˆ—è¡¨è¡¨ç¤ºæ— é”™è¯¯ï¼‰
    """

# ä½¿ç”¨ç¤ºä¾‹
errors = workflow.validate()
if errors:
    print("Workflow validation errors:")
    for error in errors:
        print(f"  - {error}")
else:
    print("Workflow is valid")
```

##### add_step() æ–¹æ³•

```python
def add_step(
    self,
    step_config: Dict[str, Any],
    position: int = None
) -> None:
    """
    æ·»åŠ å·¥ä½œæµæ­¥éª¤
    
    Args:
        step_config: æ­¥éª¤é…ç½®
        position: æ’å…¥ä½ç½®ï¼ˆNone è¡¨ç¤ºè¿½åŠ åˆ°æœ«å°¾ï¼‰
    """

# ä½¿ç”¨ç¤ºä¾‹
workflow.add_step({
    "agent": "validator",
    "input_key": "summary",
    "output_key": "validation_result",
    "conditions": ["summary != null"]
})
```

### é…ç½®ç®¡ç†

#### Config ç±»

```python
from fastagent import Config

# åŠ è½½é…ç½®
config = Config.load()  # ä»é»˜è®¤ä½ç½®åŠ è½½
config = Config.load("custom_config.yaml")  # ä»æŒ‡å®šæ–‡ä»¶åŠ è½½

# è®¿é—®é…ç½®
print(config.default_model)
print(config.anthropic.api_key)
print(config.mcp.servers)

# ä¿®æ”¹é…ç½®
config.default_model = "openai.gpt-4"
config.anthropic.api_key = "new_key"

# ä¿å­˜é…ç½®
config.save()
config.save("backup_config.yaml")
```

#### é…ç½®éªŒè¯

```python
# éªŒè¯é…ç½®
errors = config.validate()
if errors:
    print("Configuration errors:")
    for error in errors:
        print(f"  - {error}")

# æ£€æŸ¥ç‰¹å®šæä¾›å•†é…ç½®
if config.validate_provider("anthropic"):
    print("Anthropic configuration is valid")

# æµ‹è¯•è¿æ¥
results = await config.test_connections()
for provider, result in results.items():
    print(f"{provider}: {'âœ“' if result['success'] else 'âœ—'}")
```

### MCP é›†æˆ

#### MCPServer ç±»

```python
from fastagent.mcp import MCPServer

# åˆ›å»º MCP æœåŠ¡å™¨è¿æ¥
server = MCPServer(
    name="filesystem",
    transport="stdio",
    command="uvx",
    args=["mcp-server-filesystem"],
    env={"ALLOWED_DIRECTORIES": "/safe/path"}
)

# å¯åŠ¨æœåŠ¡å™¨
await server.start()

# åˆ—å‡ºå¯ç”¨å·¥å…·
tools = await server.list_tools()
print("Available tools:", [tool["name"] for tool in tools])

# è°ƒç”¨å·¥å…·
result = await server.call_tool("read_file", {"path": "/path/to/file.txt"})

# åˆ—å‡ºèµ„æº
resources = await server.list_resources()

# è·å–èµ„æº
content = await server.get_resource("file:///path/to/file.txt")

# å…³é—­æœåŠ¡å™¨
await server.close()
```

#### MCP å®¢æˆ·ç«¯

```python
from fastagent.mcp import MCPClient

# åˆ›å»ºå®¢æˆ·ç«¯
client = MCPClient()

# è¿æ¥åˆ°æœåŠ¡å™¨
await client.connect("stdio", command="uvx", args=["mcp-server-filesystem"])

# ä½¿ç”¨å®¢æˆ·ç«¯
tools = await client.list_tools()
result = await client.call_tool("read_file", {"path": "/file.txt"})

# æ–­å¼€è¿æ¥
await client.disconnect()
```

### å·¥å…·å’Œå®ç”¨å‡½æ•°

#### æ¨¡å‹ç®¡ç†

```python
from fastagent.models import ModelManager

# åˆ›å»ºæ¨¡å‹ç®¡ç†å™¨
manager = ModelManager()

# åˆ—å‡ºå¯ç”¨æ¨¡å‹
models = manager.list_models()
print("Available models:", models)

# è·å–æ¨¡å‹ä¿¡æ¯
info = manager.get_model_info("anthropic.claude-3-sonnet-latest")
print(f"Model: {info['name']}, Provider: {info['provider']}")

# éªŒè¯æ¨¡å‹
if manager.validate_model("openai.gpt-4"):
    print("Model is valid and available")

# è·å–æ¨èæ¨¡å‹
recommended = manager.get_recommended_model(task="code_generation")
print(f"Recommended model for code generation: {recommended}")
```

#### æ—¥å¿—é…ç½®

```python
from fastagent.logging import setup_logging

# åŸºæœ¬æ—¥å¿—è®¾ç½®
setup_logging(level="INFO")

# è¯¦ç»†æ—¥å¿—è®¾ç½®
setup_logging(
    level="DEBUG",
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    file="fast-agent.log",
    max_size="10MB",
    backup_count=5
)

# ç»“æ„åŒ–æ—¥å¿—
setup_logging(
    level="INFO",
    format="json",
    file="fast-agent.jsonl"
)
```

#### æ€§èƒ½ç›‘æ§

```python
from fastagent.monitoring import PerformanceMonitor

# åˆ›å»ºç›‘æ§å™¨
monitor = PerformanceMonitor()

# ç›‘æ§ä»£ç†è°ƒç”¨
@monitor.track("agent_call")
async def monitored_agent_call():
    return await agent.send("Hello")

# è·å–ç»Ÿè®¡ä¿¡æ¯
stats = monitor.get_stats()
print(f"Total calls: {stats['total_calls']}")
print(f"Average duration: {stats['avg_duration']:.2f}s")
print(f"Error rate: {stats['error_rate']:.2%}")

# å¯¼å‡ºæŒ‡æ ‡
metrics = monitor.export_prometheus_metrics()
print(metrics)
```

### å¼‚å¸¸å¤„ç†

#### å¼‚å¸¸ç±»å±‚æ¬¡ç»“æ„

```python
from fastagent.exceptions import (
    FastAgentError,      # åŸºç¡€å¼‚å¸¸
    AgentError,          # ä»£ç†ç›¸å…³é”™è¯¯
    WorkflowError,       # å·¥ä½œæµé”™è¯¯
    ModelError,          # æ¨¡å‹é”™è¯¯
    MCPError,            # MCP ç›¸å…³é”™è¯¯
    ConfigurationError,  # é…ç½®é”™è¯¯
    ValidationError,     # éªŒè¯é”™è¯¯
    TimeoutError,        # è¶…æ—¶é”™è¯¯
    RateLimitError,      # é€Ÿç‡é™åˆ¶é”™è¯¯
    AuthenticationError  # è®¤è¯é”™è¯¯
)

# å¼‚å¸¸å¤„ç†ç¤ºä¾‹
try:
    response = await agent.send("Hello")
except RateLimitError as e:
    print(f"Rate limit exceeded: {e}")
    # å®ç°é€€é¿ç­–ç•¥
    await asyncio.sleep(e.retry_after)
except AuthenticationError as e:
    print(f"Authentication failed: {e}")
    # æ£€æŸ¥ API å¯†é’¥
except ModelError as e:
    print(f"Model error: {e}")
    # å°è¯•å¤‡ç”¨æ¨¡å‹
except FastAgentError as e:
    print(f"General error: {e}")
    # é€šç”¨é”™è¯¯å¤„ç†
```

#### è‡ªå®šä¹‰å¼‚å¸¸å¤„ç†

```python
from fastagent.exceptions import FastAgentError

class CustomAgentError(FastAgentError):
    """è‡ªå®šä¹‰ä»£ç†é”™è¯¯"""
    def __init__(self, message: str, error_code: str = None):
        super().__init__(message)
        self.error_code = error_code

# ä½¿ç”¨è‡ªå®šä¹‰å¼‚å¸¸
def validate_input(data):
    if not data:
        raise CustomAgentError(
            "Input data is required",
            error_code="MISSING_INPUT"
        )
```

### é«˜çº§åŠŸèƒ½

#### æ‰¹å¤„ç†

```python
from fastagent.batch import BatchProcessor

# åˆ›å»ºæ‰¹å¤„ç†å™¨
processor = BatchProcessor(
    agent=agent,
    batch_size=10,
    max_concurrent=5
)

# æ‰¹é‡å¤„ç†æ¶ˆæ¯
messages = ["Hello", "How are you?", "What's the weather?"]
results = await processor.process_batch(messages)

for i, result in enumerate(results):
    print(f"Message {i}: {result}")
```

#### ç¼“å­˜

```python
from fastagent.cache import ResponseCache

# åˆ›å»ºç¼“å­˜
cache = ResponseCache(
    backend="redis",  # æˆ– "memory", "file"
    ttl=3600,         # 1å°æ—¶è¿‡æœŸ
    max_size=1000     # æœ€å¤§ç¼“å­˜æ¡ç›®
)

# ä½¿ç”¨ç¼“å­˜çš„ä»£ç†
cached_agent = Agent(
    instructions="You are a helpful assistant",
    model="anthropic.claude-3-sonnet-latest",
    cache=cache
)

# ç¬¬ä¸€æ¬¡è°ƒç”¨ä¼šç¼“å­˜ç»“æœ
response1 = await cached_agent.send("What is 2+2?")

# ç¬¬äºŒæ¬¡è°ƒç”¨ä¼šä»ç¼“å­˜è¿”å›
response2 = await cached_agent.send("What is 2+2?")  # ä»ç¼“å­˜è·å–

# æ¸…é™¤ç¼“å­˜
await cache.clear()
```

#### æ’ä»¶ç³»ç»Ÿ

```python
from fastagent.plugins import Plugin, PluginManager

# åˆ›å»ºè‡ªå®šä¹‰æ’ä»¶
class LoggingPlugin(Plugin):
    def __init__(self):
        super().__init__(name="logging")
    
    async def before_send(self, agent, message, context):
        print(f"Sending message to {agent.name}: {message[:50]}...")
    
    async def after_send(self, agent, message, response, context):
        print(f"Received response from {agent.name}: {response[:50]}...")
    
    async def on_error(self, agent, error, context):
        print(f"Error in {agent.name}: {error}")

# æ³¨å†Œæ’ä»¶
manager = PluginManager()
manager.register(LoggingPlugin())

# ä½¿ç”¨æ’ä»¶çš„ä»£ç†
agent = Agent(
    instructions="You are a helpful assistant",
    model="anthropic.claude-3-sonnet-latest",
    plugin_manager=manager
)
```

### å‘½ä»¤è¡Œæ¥å£

#### åŸºæœ¬å‘½ä»¤

```bash
# ç‰ˆæœ¬ä¿¡æ¯
fast-agent --version

# å¸®åŠ©ä¿¡æ¯
fast-agent --help
fast-agent <command> --help

# é…ç½®ç®¡ç†
fast-agent config init                    # åˆå§‹åŒ–é…ç½®
fast-agent config show                    # æ˜¾ç¤ºå½“å‰é…ç½®
fast-agent config validate               # éªŒè¯é…ç½®
fast-agent config set key value          # è®¾ç½®é…ç½®å€¼

# æ¨¡å‹ç®¡ç†
fast-agent models list                    # åˆ—å‡ºå¯ç”¨æ¨¡å‹
fast-agent models test <model>            # æµ‹è¯•æ¨¡å‹
fast-agent models info <model>            # æ¨¡å‹ä¿¡æ¯

# MCP ç®¡ç†
fast-agent mcp list                       # åˆ—å‡º MCP æœåŠ¡å™¨
fast-agent mcp start <server>             # å¯åŠ¨ MCP æœåŠ¡å™¨
fast-agent mcp stop <server>              # åœæ­¢ MCP æœåŠ¡å™¨
fast-agent mcp test <server>              # æµ‹è¯• MCP æœåŠ¡å™¨

# å·¥ä½œæµç®¡ç†
fast-agent workflow validate <file>       # éªŒè¯å·¥ä½œæµ
fast-agent workflow run <file>            # è¿è¡Œå·¥ä½œæµ
fast-agent workflow list                  # åˆ—å‡ºå·¥ä½œæµ

# å¿«é€Ÿå¼€å§‹
fast-agent quickstart                     # åŸºæœ¬å¿«é€Ÿå¼€å§‹
fast-agent quickstart workflow           # å·¥ä½œæµç¤ºä¾‹
fast-agent quickstart elicitations       # Elicitations ç¤ºä¾‹
fast-agent quickstart state-transfer     # çŠ¶æ€ä¼ è¾“ç¤ºä¾‹
```

#### é«˜çº§å‘½ä»¤é€‰é¡¹

```bash
# å…¨å±€é€‰é¡¹
fast-agent --config <file>               # æŒ‡å®šé…ç½®æ–‡ä»¶
fast-agent --log-level <level>           # è®¾ç½®æ—¥å¿—çº§åˆ«
fast-agent --debug                       # å¯ç”¨è°ƒè¯•æ¨¡å¼
fast-agent --profile                     # å¯ç”¨æ€§èƒ½åˆ†æ
fast-agent --no-cache                    # ç¦ç”¨ç¼“å­˜

# äº¤äº’æ¨¡å¼
fast-agent chat                          # å¯åŠ¨èŠå¤©æ¨¡å¼
fast-agent chat --agent <name>           # ä½¿ç”¨ç‰¹å®šä»£ç†
fast-agent chat --model <model>          # ä½¿ç”¨ç‰¹å®šæ¨¡å‹
fast-agent chat --system <prompt>        # è®¾ç½®ç³»ç»Ÿæç¤º

# æ‰¹å¤„ç†æ¨¡å¼
fast-agent batch <input_file>            # æ‰¹é‡å¤„ç†æ–‡ä»¶
fast-agent batch --output <file>         # æŒ‡å®šè¾“å‡ºæ–‡ä»¶
fast-agent batch --format json          # æŒ‡å®šè¾“å‡ºæ ¼å¼

# æœåŠ¡å™¨æ¨¡å¼
fast-agent serve                         # å¯åŠ¨ HTTP æœåŠ¡å™¨
fast-agent serve --port 8000             # æŒ‡å®šç«¯å£
fast-agent serve --host 0.0.0.0         # æŒ‡å®šä¸»æœº
fast-agent serve --workers 4             # æŒ‡å®šå·¥ä½œè¿›ç¨‹æ•°

# MCP æœåŠ¡å™¨æ¨¡å¼
fast-agent mcp-server                    # å¯åŠ¨ä¸º MCP æœåŠ¡å™¨
fast-agent mcp-server --transport stdio  # æŒ‡å®šä¼ è¾“æ–¹å¼
fast-agent mcp-server --agent <name>     # æŒ‡å®šä»£ç†
```

### ç¯å¢ƒå˜é‡

#### é…ç½®ç¯å¢ƒå˜é‡

```bash
# åŸºæœ¬é…ç½®
export FAST_AGENT_CONFIG_FILE="/path/to/config.yaml"
export FAST_AGENT_LOG_LEVEL="INFO"
export FAST_AGENT_DEBUG="true"

# API å¯†é’¥
export ANTHROPIC_API_KEY="your_key"
export OPENAI_API_KEY="your_key"
export AZURE_OPENAI_API_KEY="your_key"
export GOOGLE_API_KEY="your_key"
export GROQ_API_KEY="your_key"
export DEEPSEEK_API_KEY="your_key"

# æ¨¡å‹é…ç½®
export FAST_AGENT_DEFAULT_MODEL="anthropic.claude-3-sonnet-latest"
export FAST_AGENT_TEMPERATURE="0.7"
export FAST_AGENT_MAX_TOKENS="4000"

# MCP é…ç½®
export FAST_AGENT_MCP_TIMEOUT="30"
export FAST_AGENT_MCP_RETRY_ATTEMPTS="3"

# æ€§èƒ½é…ç½®
export FAST_AGENT_CACHE_ENABLED="true"
export FAST_AGENT_CACHE_TTL="3600"
export FAST_AGENT_MAX_CONCURRENT="10"

# å®‰å…¨é…ç½®
export FAST_AGENT_ALLOWED_HOSTS="localhost,127.0.0.1"
export FAST_AGENT_CORS_ORIGINS="*"
export FAST_AGENT_API_KEY_REQUIRED="false"
```

### ç±»å‹å®šä¹‰

#### æ ¸å¿ƒç±»å‹

```python
from typing import Dict, List, Any, Optional, Union, Callable, AsyncGenerator
from dataclasses import dataclass
from enum import Enum

# æ¶ˆæ¯ç±»å‹
@dataclass
class Message:
    role: str  # "user", "assistant", "system"
    content: str
    timestamp: Optional[float] = None
    metadata: Optional[Dict[str, Any]] = None

# å·¥å…·å®šä¹‰
@dataclass
class Tool:
    name: str
    description: str
    parameters: Dict[str, Any]
    function: Optional[Callable] = None

# æ¨¡å‹é…ç½®
@dataclass
class ModelConfig:
    provider: str
    model: str
    api_key: Optional[str] = None
    base_url: Optional[str] = None
    temperature: Optional[float] = None
    max_tokens: Optional[int] = None
    timeout: Optional[int] = None

# å·¥ä½œæµæ­¥éª¤
@dataclass
class WorkflowStep:
    agent: str
    input_key: str
    output_key: str
    conditions: Optional[List[str]] = None
    error_handling: Optional[Dict[str, Any]] = None

# å·¥ä½œæµç±»å‹
class WorkflowType(Enum):
    CHAIN = "chain"
    PARALLEL = "parallel"
    HUMAN_INPUT = "human_input"
    EVALUATOR_OPTIMIZER = "evaluator_optimizer"
    ROUTER = "router"
    ORCHESTRATOR = "orchestrator"

# MCP ä¼ è¾“ç±»å‹
class MCPTransport(Enum):
    STDIO = "stdio"
    HTTP = "http"
    SSE = "sse"

# å“åº”ç±»å‹
ResponseType = Union[str, Dict[str, Any], List[Any]]
StreamResponse = AsyncGenerator[str, None]
```

### é…ç½®æ¨¡å¼

#### YAML é…ç½®æ¨¡å¼

```yaml
# fastagent.config.yaml å®Œæ•´æ¨¡å¼
default_model: string                    # é»˜è®¤æ¨¡å‹
auto_sampling: boolean                   # è‡ªåŠ¨é‡‡æ ·
temperature: number                      # é»˜è®¤æ¸©åº¦
max_tokens: integer                      # é»˜è®¤æœ€å¤§ä»¤ç‰Œ

# æ¨¡å‹æä¾›å•†é…ç½®
anthropic:
  api_key: string
  base_url: string
  timeout: integer
  max_retries: integer

openai:
  api_key: string
  organization: string
  base_url: string
  timeout: integer

azure_openai:
  api_key: string
  endpoint: string
  api_version: string
  deployment_name: string

# MCP æœåŠ¡å™¨é…ç½®
mcp:
  servers:
    server_name:
      transport: "stdio" | "http" | "sse"
      command: string
      args: [string]
      env: {string: string}
      cwd: string
      timeout: integer
      retry_attempts: integer

# Elicitations é…ç½®
elicitations:
  forms:
    form_name:
      title: string
      description: string
      fields:
        field_name:
          type: "text" | "number" | "select" | "checkbox"
          label: string
          required: boolean
          options: [string]  # for select type
          default: any

# æ—¥å¿—é…ç½®
logging:
  level: "DEBUG" | "INFO" | "WARNING" | "ERROR"
  format: "text" | "json"
  file: string
  max_size: string
  backup_count: integer

# æ€§èƒ½é…ç½®
performance:
  cache:
    enabled: boolean
    backend: "memory" | "redis" | "file"
    ttl: integer
    max_size: integer
  
  connection_pool:
    max_connections: integer
    max_keepalive_connections: integer
    keepalive_expiry: integer
  
  timeouts:
    connect: integer
    read: integer
    total: integer
  
  concurrency:
    max_concurrent_requests: integer
    semaphore_size: integer

# å®‰å…¨é…ç½®
security:
  allowed_hosts: [string]
  cors_origins: [string]
  api_key_required: boolean
  rate_limiting:
    requests_per_minute: integer
    burst_size: integer
```

## æ€»ç»“

æœ¬ API å‚è€ƒæ–‡æ¡£æ¶µç›–äº† `fast-agent` çš„æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½ï¼š

1. **æ ¸å¿ƒç±»**ï¼šAgentã€Workflowã€Config ç­‰ä¸»è¦ç±»çš„è¯¦ç»† API
2. **æ–¹æ³•å’Œå±æ€§**ï¼šæ‰€æœ‰å…¬å…±æ–¹æ³•çš„å‚æ•°ã€è¿”å›å€¼å’Œä½¿ç”¨ç¤ºä¾‹
3. **å¼‚å¸¸å¤„ç†**ï¼šå®Œæ•´çš„å¼‚å¸¸ç±»å±‚æ¬¡ç»“æ„å’Œå¤„ç†ç­–ç•¥
4. **é«˜çº§åŠŸèƒ½**ï¼šæ‰¹å¤„ç†ã€ç¼“å­˜ã€æ’ä»¶ç­‰é«˜çº§ç‰¹æ€§
5. **å‘½ä»¤è¡Œæ¥å£**ï¼šæ‰€æœ‰ CLI å‘½ä»¤å’Œé€‰é¡¹
6. **é…ç½®ç®¡ç†**ï¼šç¯å¢ƒå˜é‡å’Œé…ç½®æ–‡ä»¶çš„å®Œæ•´å‚è€ƒ
7. **ç±»å‹å®šä¹‰**ï¼šTypeScript é£æ ¼çš„ç±»å‹æ³¨è§£

è¿™ä¸ªå‚è€ƒæ–‡æ¡£å¯ä»¥ä½œä¸ºå¼€å‘æ—¶çš„å¿«é€ŸæŸ¥è¯¢æ‰‹å†Œï¼Œå¸®åŠ©æ‚¨å……åˆ†åˆ©ç”¨ `fast-agent` çš„æ‰€æœ‰åŠŸèƒ½ã€‚

---

**æ•™ç¨‹ç³»åˆ—å®Œæˆï¼** ğŸ‰

æ‚¨ç°åœ¨å·²ç»æŒæ¡äº† `fast-agent` çš„å®Œæ•´çŸ¥è¯†ä½“ç³»ï¼Œä»åŸºç¡€å…¥é—¨åˆ°é«˜çº§åº”ç”¨ï¼Œä»é…ç½®ç®¡ç†åˆ°æ•…éšœæ’é™¤ï¼Œåº”æœ‰å°½æœ‰ã€‚å¼€å§‹æ„å»ºæ‚¨çš„æ™ºèƒ½ä»£ç†åº”ç”¨å§ï¼